{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceqZP6alWvMF"
   },
   "source": [
    "PUNTAJE 2.4062"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "KFwy6Btgu5Bj"
   },
   "source": [
    "from google.colab import files \n",
    "files.upload()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "yKw-jnFCJJTL"
   },
   "source": [
    "# ***Descargar Dataset desde kaggle***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHtfJnDYEGII",
    "outputId": "e99407f5-fda4-48b8-cf1e-56932ea7752e"
   },
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4o7PxdVGhXj",
    "outputId": "df5ee177-17cd-43b8-8435-3eea1d15d5ca"
   },
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "wT8Usj-GGnN_"
   },
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1lAX0zaxGzmz"
   },
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bskbr8kHG-RR",
    "outputId": "7c61a2eb-0ab5-4b0e-fe01-44e218cf9721"
   },
   "source": [
    "! kaggle competitions download -c store-sales-time-series-forecasting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53EMwBlNHg_l",
    "outputId": "ed71ed14-68ca-465d-f55f-1cbff228aa30"
   },
   "source": [
    "! unzip store-sales-time-series-forecasting.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "aIFhzuLoIB-b"
   },
   "source": [
    "! rm store-sales-time-series-forecasting.zip\n",
    "! rm kaggle.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he7OyiU7znYv"
   },
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../Datasets/store-sales-time-series-forecasting/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHndxsRn7UAi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRyj5h0e7VYh"
   },
   "outputs": [],
   "source": [
    "# Load train\n",
    "train_data = pd.read_csv(path+'train.csv', parse_dates=['date'], infer_datetime_format=True) # columna date a tipo fecha\n",
    "# Load Test\n",
    "test_data = pd.read_csv(path+'test.csv', parse_dates=['date'], infer_datetime_format=True) # columna date a tipo fecha\n",
    "#Load stores\n",
    "stores_data = pd.read_csv(path+'stores.csv')\n",
    "#Load oil \n",
    "oil_data = pd.read_csv(path+'oil.csv',parse_dates=['date'], infer_datetime_format=True)\n",
    "#Load holidays\n",
    "holiday_data= pd.read_csv(path+'holidays_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdMtLJbjQMmt"
   },
   "source": [
    "# **ANALISIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qmb4YLYwu1ro"
   },
   "source": [
    "## **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQ9RdWvYu1ro",
    "outputId": "ae81d9ca-cf6d-46c4-9195-ad43cb4d6743"
   },
   "outputs": [],
   "source": [
    "# Cuantas tiendas , productos y fechas hay en el dataset\n",
    "\n",
    "print('Stores : ',train_data['store_nbr'].unique().__len__()) # 54 stores\n",
    "print('Families : ',train_data['family'].unique().__len__()) # 33 products\n",
    "\n",
    "print('Dias en train data : ',len(train_data) / 54 / 33) # 1684 days (between 4 and 5 years)\n",
    "print('Fecha Inicial Train : ',train_data['date'].iloc[0]) # 2013-01-01 is start\n",
    "print('Fecha Final Train : ',train_data['date'].iloc[-1]) # 2017-08-15 is end\n",
    "\n",
    "print('Dias en test data : ',len(test_data) / 54 / 33) # 16 days\n",
    "print('Fecha Inicial Test : ',test_data['date'].iloc[0]) # 2017-08-16 is test start\n",
    "print('Fecha Final Test : ',test_data['date'].iloc[-1]) # 2017-08-31 is test test_df\n",
    "\n",
    "print('Registros totales en train : ',train_data['id'].unique().__len__())\n",
    "print('Registros totales en Test : ',test_data['id'].unique().__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uHcgvhbu1rp"
   },
   "source": [
    "Podemos observar que tanto los datos en Train como Test se distribuyen de la siguiente manera : \n",
    "Tenemos 33 familias de productos , en 54 tiendas con un registro de ventas en 1684 dias (desde la fecha inicial hasta la fecha final del dataset ) , esto es 33*54*1684 = 3000888 registros .\n",
    "Cada registro representa la venta de un producto (familia) en una tienda especifica (store_nbr) en un dia (date) , los datos estan entre 2013-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGzLaZVWu1rp",
    "outputId": "82102093-db2e-4f64-ca0f-f58845368264",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = train_data.copy()\n",
    "data = data.set_index(\"date\").to_period('D')\n",
    "data = data.groupby('date').agg({'sales':'mean'})\n",
    "#Grafica interactiva \n",
    "data =data.iloc[1:, :].reset_index()\n",
    "data['date']=data['date'].apply(lambda x: x.to_timestamp())\n",
    "# data\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame = data,\n",
    "    x      = 'date',\n",
    "    y      = 'sales', \n",
    "    title  = 'Ventas diarias',\n",
    "    width  = 900,\n",
    "    height = 500\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Khq3tYdmu1rq"
   },
   "source": [
    "La grafica anterior de ventas diaras , nos da un indicio de que hay un patron de ventas dependiendo del los dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6nO79SBu1rq",
    "outputId": "575dea4d-aadd-4dbd-bbca-5680455acd97"
   },
   "outputs": [],
   "source": [
    "data = train_data.copy()\n",
    "data['day_of_week'] = data['date'].dt.weekday\n",
    "sales_by_day = data.groupby('day_of_week')['sales'].mean()\n",
    "\n",
    "# Crear un gráfico de barras para visualizar las ventas por día de la semana\n",
    "plt.bar(sales_by_day.index, sales_by_day.values)\n",
    "plt.xticks(range(7), ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo'])\n",
    "plt.xlabel('Día de la semana')\n",
    "plt.ylabel('Ventas promedio')\n",
    "plt.title('Ventas promedio por día de la semana')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg_4tvkwu1rq"
   },
   "source": [
    "por lo general los fines de semana son los dias de mas ventas , lo que indica que una buena caracteristica por añadir al dataset podria ser el dia de la semana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tuI5IR7u1rr"
   },
   "source": [
    "## Stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pp8ZBezVu1rr",
    "outputId": "fa4762d6-460d-4ded-f30c-c4752bd83572"
   },
   "outputs": [],
   "source": [
    "#Grafica relacion entre stores y train\n",
    "merged = pd.merge(train_data, stores_data, on='store_nbr', how='left')\n",
    "sales_by_type = merged.groupby('type')['sales'].mean()\n",
    "sales_by_type.plot(kind='bar')\n",
    "plt.xlabel('Store Type')\n",
    "plt.ylabel('Total Ventas')\n",
    "plt.title('Total ventas por tipo de tienda')\n",
    "plt.show()\n",
    "sales_by_cluster = merged.groupby('cluster')['sales'].mean()\n",
    "sales_by_cluster.plot(kind='bar')\n",
    "plt.xlabel('Store Cluster')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Total ventas por cluster type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b-ehEn0u1rr"
   },
   "source": [
    "Se observa una fuerte relacion entre las tiendas y el promedio de ventas , dado que esto puede afectar en la prediccion se tendra en cuenta los datos de stores , para esto combinamos los dataframe para tener ambos datos, se hace el mismo proceso con test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Og-yraFJu1rs"
   },
   "source": [
    "## Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpBm2F5Xu1rs",
    "outputId": "e68cabd3-a034-4e2f-8b0c-d95ab8286459"
   },
   "outputs": [],
   "source": [
    "\n",
    "merged = pd.merge(train_data, oil_data, on='date', how='left')\n",
    "\n",
    "print(\"Correlation with Daily Oil Prices\")\n",
    "print((merged['dcoilwtico']).corr(merged[\"sales\"]), \"\\n\")\n",
    "\n",
    "# Create scatter plot of sales versus oil price\n",
    "plt.scatter(merged['dcoilwtico'], merged['sales'])\n",
    "plt.xlabel('Oil Price')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Sales vs Oil Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMT_36sFu1rs"
   },
   "source": [
    "Se tiene una correlacion entre las ventas diarias y el precio del petroleo de (-0.079), al ser negativo indica que las ventas diarias desminuyen cuando el precio del petroleo aumenta pero no es una relacion fuerte , inicialmente no se tendra en cuenta este archivo , pero se tendra en cuenta para futuros cambios al modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HL6g6pCz7Y2t"
   },
   "outputs": [],
   "source": [
    "# Merge the oil price data with the training and test data\n",
    "# train_data = pd.merge(train_data, oil_data, on='date', how='left')\n",
    "# test_data = pd.merge(test_data, oil_data, on='date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IrGLTd3u1rt"
   },
   "source": [
    "# **MODELO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6LqH4lKu1rt"
   },
   "source": [
    "## Organizando y limpiando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7T9CysfY7buB"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Separando date en sus componentes dia , mes .año y dia de la semana\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "train_data['day_of_week'] = train_data['date'].dt.dayofweek\n",
    "train_data['month'] = train_data['date'].dt.month\n",
    "train_data['year'] = train_data['date'].dt.year\n",
    "\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "test_data['day_of_week'] = test_data['date'].dt.dayofweek\n",
    "test_data['month'] = test_data['date'].dt.month\n",
    "test_data['year'] = test_data['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmVck1Qy9AEB"
   },
   "outputs": [],
   "source": [
    "# train_data['dcoilwtico'] = train_data['dcoilwtico'].fillna(0)\n",
    "# train_data['onpromotion'] =train_data['onpromotion'].fillna(0)\n",
    "# test_data['dcoilwtico'] = test_data['dcoilwtico'].fillna(0)\n",
    "# test_data['onpromotion'] =test_data['onpromotion'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UionbSau1ru"
   },
   "outputs": [],
   "source": [
    "# Merge \n",
    "# Merge de train y test con stores\n",
    "train_data = pd.merge(train_data, stores_data, on='store_nbr', how='left')\n",
    "test_data = pd.merge(test_data, stores_data, on='store_nbr', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1NAy-B57dbH"
   },
   "outputs": [],
   "source": [
    "# Codificando variables categoricas\n",
    "train_data = pd.get_dummies(train_data, columns=['family', 'type', 'city', 'state', 'cluster'])\n",
    "test_data = pd.get_dummies(test_data, columns=['family', 'type', 'city', 'state', 'cluster'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7INTyXtB7xBs",
    "outputId": "09e5fb97-a4dc-412e-eb0e-bab7314c35d4"
   },
   "outputs": [],
   "source": [
    "# nan data validation\n",
    "test_data.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HP4JN45ZXNmJ",
    "outputId": "fa4928ce-3fa1-41e0-fcc2-9e6fc91ed077"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9v__xIW7fxl",
    "outputId": "f8ab35ec-de04-4633-9667-75e679765f86"
   },
   "outputs": [],
   "source": [
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data.drop(['date', 'sales'], axis=1), train_data['sales'], test_size=0.2, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLRCksIl7hU7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train a Random Forest Regression model\n",
    "model = RandomForestRegressor(n_estimators=50,max_depth=5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "K5m86FBs9Osy",
    "outputId": "ed456977-994b-4820-b45a-2e44ce7cbe39"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt3Ss6H27kTg"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5Yn2SE17mKE",
    "outputId": "3dccd228-6ba9-4f60-a9cc-434915b4f60d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the RMSLE of the predictions\n",
    "rmsle_score = np.sqrt(mean_squared_error(np.log1p(y_val), np.log1p(y_val_pred)))\n",
    "print('RMSLE: ', rmsle_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDJq34l27od5"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "X_test = test_data.drop([ 'date'], axis=1)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_m2JhRNGCsS"
   },
   "outputs": [],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWU7qs227BHp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a submission file\n",
    "# submission = pd.DataFrame({'id': test_data['id'], 'sales': y_test_pred})\n",
    "# submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yKw-jnFCJJTL"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
