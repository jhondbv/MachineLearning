{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/lucasbenazzicestari/store-sales-time-series-prediction/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer** - This notebook will focus only on making predictions for the Store Sales - Time Series Forecasting competition; it won't do any in-depth analysis as there are already plenty of well-made resources available for that.\n",
    "\n",
    "# **Introduction**\n",
    "The predictions will be made using the already available datasets from the competition. The sales information is divided into product families, so each day there's information on how much a product family is sold as well as how many were on promotion. There is also oil price information available, which will be useful as Ecuador is an oil-dependent country. And finally, there's information on all holidays and relevant events for the country.\n",
    "\n",
    "# **Objective**\n",
    "The goal of this notebook will be to create multiple models for each store, average their predictions, and make a competition submission. In order to do this, we will preprocess the data and create a Store class to make individual predictions.\n",
    "\n",
    "# **Relevant datasets**\n",
    "**Oil** - This dataset consists only of the oil prices for each given day. This information needs some preprocessing as there are some missing values. In addition to this, two columns will be added, one with the moving average and another with the moving standard deviation.\n",
    "\n",
    "**Holidays Events** - This dataset has a description of all events and holidays and which regions of the country were affected. Since we have the region for each store, we can see which holidays and events affected which stores. The dataset still needs to have transformations done in order to get a list of affected stores. Alongside of that, there are many different types of holidays and events that happened during this period, so there will be many simplifications. The goal will be to determine, for each store, if a given day had an event or holiday, and classify that date as \"Non working day\".\n",
    "\n",
    "**Stores** - For each store, there's information on product families being sold and being on promotion. Since the goal is to predict sales, product family sales will be used as the label and promotion information will be used as input for training the model.\n",
    "\n",
    "# **Prediction**\n",
    "Two models will be trained: XGBoost and Random Forest regressor. The final prediction will be the average of the predictions of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T07:26:11.864752Z",
     "iopub.status.busy": "2022-04-28T07:26:11.864239Z",
     "iopub.status.idle": "2022-04-28T07:26:13.047265Z",
     "shell.execute_reply": "2022-04-28T07:26:13.046533Z",
     "shell.execute_reply.started": "2022-04-28T07:26:11.864713Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from calendar import monthrange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T07:26:13.049153Z",
     "iopub.status.busy": "2022-04-28T07:26:13.048885Z",
     "iopub.status.idle": "2022-04-28T07:26:16.17533Z",
     "shell.execute_reply": "2022-04-28T07:26:16.174609Z",
     "shell.execute_reply.started": "2022-04-28T07:26:13.049115Z"
    }
   },
   "outputs": [],
   "source": [
    "path='../Datasets/store-sales-time-series-forecasting/'\n",
    "df_holidays_events = pd.read_csv(path+\"holidays_events.csv\",\n",
    "                                 parse_dates = ['date'])\n",
    "\n",
    "df_oil = pd.read_csv(path+\"oil.csv\",\n",
    "                     parse_dates = ['date'])\n",
    "\n",
    "df_stores = pd.read_csv(path+\"stores.csv\")\n",
    "\n",
    "df_test = pd.read_csv(path+\"test.csv\",\n",
    "                      parse_dates = ['date'])\n",
    "\n",
    "df_train = pd.read_csv(path+\"train.csv\",\n",
    "                      parse_dates = ['date'])\n",
    "\n",
    "df_sample_submission = pd.read_csv(path+\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Oil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T07:26:16.178224Z",
     "iopub.status.busy": "2022-04-28T07:26:16.177588Z",
     "iopub.status.idle": "2022-04-28T07:26:16.203449Z",
     "shell.execute_reply": "2022-04-28T07:26:16.202843Z",
     "shell.execute_reply.started": "2022-04-28T07:26:16.178185Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing oil data and adds two columns\n",
    "oil = df_oil.copy()\n",
    "oil = oil.set_index('date')\n",
    "oil = oil['dcoilwtico'].resample('D').sum().reset_index()\n",
    "oil = oil.replace({0:np.nan})\n",
    "oil['dcoilwtico'] = oil['dcoilwtico'].interpolate(limit_direction = 'both')\n",
    "oil['dcoilwtico mean'] = oil['dcoilwtico'].rolling(7).mean().interpolate(limit_direction = 'both')\n",
    "oil['dcoilwtico std'] = oil['dcoilwtico'].rolling(7).std().interpolate(limit_direction = 'both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Holiday and Events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T07:26:16.205687Z",
     "iopub.status.busy": "2022-04-28T07:26:16.205308Z",
     "iopub.status.idle": "2022-04-28T07:26:16.318013Z",
     "shell.execute_reply": "2022-04-28T07:26:16.317325Z",
     "shell.execute_reply.started": "2022-04-28T07:26:16.205653Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining which stores were affected by which event or holiday\n",
    "holidays_events = df_holidays_events.copy()\n",
    "\n",
    "# the next couple of changes were made analysing the data. There was an official transfer for new years eve holiday, but that didn't translate on a difference in sales.\n",
    "holidays_events.loc[297, 'transferred'] = False\n",
    "holidays_events = holidays_events.loc[~(holidays_events.index == 298)]\n",
    "\n",
    "holidays_events = holidays_events.loc[holidays_events['transferred'] == False].drop('transferred', axis = 1)\n",
    "holidays_events = holidays_events.loc[holidays_events['type'] != \"Work Day\"]\n",
    "\n",
    "stores = df_stores.copy()\n",
    "\n",
    "def affected_stores(holiday_locale, holiday_locale_name):\n",
    "    if holiday_locale == 'National':\n",
    "        return stores['store_nbr'].unique()\n",
    "    \n",
    "    elif holiday_locale == 'Local':\n",
    "        return stores['store_nbr'].loc[stores['city'] == holiday_locale_name].to_numpy()\n",
    "    elif holiday_locale == 'Regional':\n",
    "        return stores['store_nbr'].loc[stores['state'] == holiday_locale_name].to_numpy()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "holidays_events['cities'] = holidays_events.apply(lambda x : affected_stores(x['locale'],x['locale_name']), axis = 1)\n",
    "\n",
    "holidays_events = holidays_events.drop(columns = ['type','locale','locale_name','description'], axis = 0)\n",
    "\n",
    "cities_dummies = cities_dummies = pd.get_dummies(holidays_events['cities'].explode()).sum(level=0)\n",
    "holidays_with_dummies = pd.concat([holidays_events, cities_dummies], axis = 1).drop(['cities'], axis = 1)\n",
    "\n",
    "holidays_events = pd.melt(holidays_with_dummies, id_vars = 'date', var_name = 'store_nbr').drop(['value'], axis = 1)\n",
    "holidays_by_store = holidays_events.groupby(['date','store_nbr']).sum().reset_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T07:26:16.319615Z",
     "iopub.status.busy": "2022-04-28T07:26:16.319361Z",
     "iopub.status.idle": "2022-04-28T07:26:16.349573Z",
     "shell.execute_reply": "2022-04-28T07:26:16.348847Z",
     "shell.execute_reply.started": "2022-04-28T07:26:16.319579Z"
    }
   },
   "outputs": [],
   "source": [
    "class AuxiliaryFunctions():\n",
    "    \"\"\"Class with auxiliary functions to be used in the\n",
    "    Store class.\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_first_day_sold(self, store_nbr):\n",
    "        \"\"\"Gets the day the given store had its first\n",
    "        sale.\n",
    "        \n",
    "        Args:\n",
    "            store_nbr (int): Unique id of the store.\n",
    "        Returns:\n",
    "            Datetime of the first sale.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        df = df_train.copy()\n",
    "        df = df.loc[df['store_nbr'] == store_nbr, ['date','sales']]\n",
    "        df = df.groupby('date').sum()\n",
    "        return df.ne(0).idxmax().values[0] + np.timedelta64(1,'D')\n",
    "\n",
    "    def prepare_test_inputs(self, store_nbr, start_date, end_date):\n",
    "        \"\"\"Gets the input and label values from the train\n",
    "        dataframe with their relevant values unstacked. It\n",
    "        takes two dates as input to use as a date range.\n",
    "        \n",
    "        X input has the family column unstacked with the\n",
    "        promotion values.\n",
    "        y input has the family column unstacked with the\n",
    "        sales values.\n",
    "        \n",
    "        Args:\n",
    "            start_date (Datetime): Day from which to start.\n",
    "            end_date (Datetime): Day from which to end.\n",
    "            \n",
    "        Returns:\n",
    "            The inputs (X) and labels (y) for training.\n",
    "        \"\"\"\n",
    "        \n",
    "        df = df_train.copy()\n",
    "\n",
    "        df = df.loc[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "        df = df.set_index(['family','date']).sort_index().drop('id', axis = 1)\n",
    "        \n",
    "        X = df.loc[df['store_nbr'] == store_nbr].drop(['store_nbr','sales'], axis = 1).unstack('family')\n",
    "        X.columns = [name for _, name in X.columns]\n",
    "        \n",
    "        y = df.loc[df['store_nbr'] == self.store_nbr].drop(['store_nbr','onpromotion'], axis = 1).unstack('family')\n",
    "        y.columns = [name for _, name in y.columns]\n",
    "        \n",
    "        X = X.reset_index()\n",
    "        return X, y      \n",
    "    \n",
    "    def add_information(self, dataframe):\n",
    "        \"\"\"Adds relevant data not directly present in the\n",
    "        train dataframe.\n",
    "\n",
    "        It adds data related to oil prices, time information,\n",
    "        and which dates to consider as work days.\n",
    "\n",
    "        Args:\n",
    "            dataframe (DataFrame): Base dataframe which will\n",
    "                have the information added.\n",
    "\n",
    "        Returns:\n",
    "            A dataframe with its base values and extra\n",
    "            information combined.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        X = dataframe.copy()\n",
    "\n",
    "        X = X.merge(oil, on = ['date'], how = 'left')\n",
    "\n",
    "        timestamp_s = X['date'].map(pd.Timestamp.timestamp)\n",
    "\n",
    "        day = 24 * 60 * 60\n",
    "        week = day * 7\n",
    "        year = 365.2425 * day\n",
    "        quarter = year / 4\n",
    "        half_decade = year * 5\n",
    "\n",
    "        X['week sin'] = np.sin(timestamp_s * (2 * np.pi / week))\n",
    "        X['week cos'] = np.cos(timestamp_s * (2 * np.pi / week))\n",
    "\n",
    "        X['quarter sin'] = np.sin(timestamp_s * (2 * np.pi / quarter))\n",
    "        X['quarter cos'] = np.cos(timestamp_s * (2 * np.pi / quarter))\n",
    "\n",
    "        X['year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "        X['year cos'] = np.cos(timestamp_s * (2 * np.pi / year))    \n",
    "\n",
    "        X['half decade sin'] = np.sin(timestamp_s * (2 * np.pi / half_decade))\n",
    "        X['half decade cos'] = np.cos(timestamp_s * (2 * np.pi / half_decade))    \n",
    "\n",
    "        X['day of week'] = X['date'].dt.dayofweek\n",
    "\n",
    "        X['is new year'] = 0\n",
    "        X.loc[X['date'].dt.dayofyear == 1, 'is new year'] = 1\n",
    "\n",
    "        X['is work day'] = 1\n",
    "        X['quarter'] = X['date'].dt.month // 4\n",
    "\n",
    "        store_holidays = holidays_by_store.loc[holidays_by_store['store_nbr'] == self.store_nbr, 'date']\n",
    "        X.loc[\n",
    "            (X['date'].isin(store_holidays)) | (X['day of week'] > 4) |\n",
    "            (X['date'].dt.day == 15)\n",
    "            ,\n",
    "            'is work day'] = 0\n",
    "\n",
    "        X['is payday'] = X['date'].map(\n",
    "            lambda date: 1 if (date.day == monthrange(date.year, date.month)[1] or date.day == 15) else 0\n",
    "        )\n",
    "        X = pd.get_dummies(X, columns = ['day of week'])\n",
    "\n",
    "        return X.set_index('date')\n",
    "\n",
    "    def train_test_split(self, store_nbr, number_of_days = 15):\n",
    "        \"\"\"Creates a train test split based on a given number\n",
    "        of days, which specifies the number of days used for\n",
    "        testing. The split isn't randomized and the test data\n",
    "        is always after the training data.\n",
    "        \n",
    "        Args:\n",
    "            store_nbr (int): Unique id of the store.\n",
    "            number_of_days (int): Number of days to be use for the\n",
    "                test data.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        train_start_date = self.get_first_day_sold(store_nbr)\n",
    "        train_end_date = df_train['date'].max() - np.timedelta64(number_of_days, 'D')\n",
    "        \n",
    "        X_train, y_train = self.prepare_test_inputs(store_nbr, train_start_date, train_end_date)\n",
    "        X_train = self.add_information(X_train)\n",
    "        \n",
    "        val_start_date = train_end_date + np.timedelta64(1, 'D')\n",
    "        val_end_date = df_train['date'].max()\n",
    "    \n",
    "        X_test, y_test = self.prepare_test_inputs(store_nbr, val_start_date, val_end_date)\n",
    "        X_test = self.add_information(X_test)\n",
    "    \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    def get_input_for_prediction(self):\n",
    "        \"\"\"Gets the inputs from the test dataframe that will\n",
    "        be used to make the final prediction. This function\n",
    "        also calls the self.add_information method to prepare\n",
    "        the dataframe.\n",
    "        \n",
    "        Returns:\n",
    "            Dataframe will all necessary information for\n",
    "            prediction.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        df = df_test.copy()\n",
    "        df = df.set_index(['family','date']).sort_index().drop('id', axis = 1)\n",
    "        \n",
    "        X = df.loc[df['store_nbr'] == self.store_nbr].drop(['store_nbr'], axis = 1).unstack('family')\n",
    "        X.columns = X.columns.map(' - '.join).str.strip(' - ')\n",
    "        X = X.reset_index()\n",
    "        X = self.add_information(X)\n",
    "        return X\n",
    "    \n",
    "    def merge_to_prediction(self, y_pred, y_columns, X_pred):\n",
    "        \"\"\"This function returns the prediction in the same\n",
    "        format as the sample_submission file.\n",
    "        \n",
    "        Args:\n",
    "            y_pred (np.array): Values predicted.\n",
    "            y_columns (list): Column names.\n",
    "            X_pred (DataFrame): Dataframe used for prediction.\n",
    "        \n",
    "        Returns:\n",
    "            Section of submission for the given store.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        prediction = pd.DataFrame(y_pred, columns = y_columns, index = X_pred.index).unstack()\n",
    "        prediction = prediction.reset_index().set_index('date').rename(columns = {0: \"sales\", \"level_0\":\"family\"})\n",
    "        prediction['store_nbr'] = self.store_nbr\n",
    "        submission = df_test.copy()\n",
    "        current_submission = submission.merge(prediction.reset_index(), how = 'inner')\n",
    "        \n",
    "        return current_submission\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Store models class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T07:26:16.351288Z",
     "iopub.status.busy": "2022-04-28T07:26:16.350945Z",
     "iopub.status.idle": "2022-04-28T07:26:16.364502Z",
     "shell.execute_reply": "2022-04-28T07:26:16.363787Z",
     "shell.execute_reply.started": "2022-04-28T07:26:16.351252Z"
    }
   },
   "outputs": [],
   "source": [
    "class Store(AuxiliaryFunctions):\n",
    "    \"\"\"Class for handling the training and prediction of a\n",
    "    XGBRegressor and RandomForestRegressor models. Both\n",
    "    model predictions are averaged out before submitting\n",
    "    the results.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, store_nbr):\n",
    "        \"\"\"Setting up all necessary attributes for training\n",
    "        and prediction.\n",
    "        \n",
    "        Args:\n",
    "            store_nbr (int): Unique id of the store.\n",
    "            \n",
    "        Attributes:\n",
    "            store_nbr (int): Unique id of the store.\n",
    "            random_state (int): Set seed for the random\n",
    "                number generator.\n",
    "            X_train, y_train (DataFrame): Dataframes for\n",
    "                training the model.\n",
    "            X_test, y_test (DataFrame): Dataframes for\n",
    "                testing the model.\n",
    "            X, y (DataFrame): Dataframes that are a\n",
    "                combination of training and testing data.\n",
    "            xgb_model: XGBoost regressor model.\n",
    "            random_forest_model: Random Forest regressor\n",
    "                model.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.store_nbr = store_nbr\n",
    "        \n",
    "        self.random_state = 42\n",
    "        \n",
    "        self.X_train, self.y_train, self.X_test, self.y_test = self.train_test_split(self.store_nbr)\n",
    "        \n",
    "        self.X, self.y, _, _ = self.train_test_split(self.store_nbr, 0)\n",
    "        \n",
    "        self.xgb_model = MultiOutputRegressor(XGBRegressor(booster = \"gbtree\", random_state = self.random_state))\n",
    "        self.random_forest_model = RandomForestRegressor(n_estimators = 150, random_state = self.random_state)\n",
    "        \n",
    "    def train_models(self):\n",
    "        \"\"\"Trains both models with the training data.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.xgb_model.fit(self.X_train, self.y_train)\n",
    "        self.random_forest_model.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Uses the testing data to evaluate each model, as\n",
    "        well as the combination of the two.\n",
    "        \n",
    "        Returns:\n",
    "            evaluation_xgb (float): mean squared log error\n",
    "                of the XGBoost regressor model.\n",
    "            evaluation_forest (float): mean squared log error\n",
    "                of the Random Forest regressor model.\n",
    "            evaluation_average (float): mean squared log error\n",
    "                of the average prediction of the two models.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred_xgb = self.xgb_model.predict(self.X_test).clip(0.0)\n",
    "        y_pred_forest = self.random_forest_model.predict(self.X_test).clip(0.0)\n",
    "        \n",
    "        y_pred_average = (y_pred_xgb + y_pred_forest) / 2\n",
    "        \n",
    "        evaluation_xgb = mean_squared_log_error(y_pred_xgb, self.y_test.to_numpy())\n",
    "        evaluation_forest = mean_squared_log_error(y_pred_forest, self.y_test.to_numpy())\n",
    "        \n",
    "        evaluation_average = mean_squared_log_error(y_pred_average, self.y_test.to_numpy())\n",
    "        \n",
    "        return evaluation_xgb, evaluation_forest, evaluation_average\n",
    "    \n",
    "    def train_and_predict(self):\n",
    "        \"\"\"Trains both models using all available testing data,\n",
    "        and returns a formatted prediction.\n",
    "        \n",
    "        Returns:\n",
    "            A dataframe with the current predictions with the\n",
    "            same formating as the sample_submission.csv file.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.xgb_model.fit(self.X, self.y)\n",
    "        \n",
    "        self.random_forest_model.fit(self.X, self.y)\n",
    "        \n",
    "        X_pred = self.get_input_for_prediction()\n",
    "        \n",
    "        y_pred_xgb_final = self.xgb_model.predict(X_pred).clip(0.0)\n",
    "        y_pred_random_forrest_final = self.random_forest_model.predict(X_pred).clip(0.0)\n",
    "        \n",
    "        y_pred = (y_pred_xgb_final + y_pred_random_forrest_final) / 2\n",
    "        \n",
    "        return self.merge_to_prediction(y_pred, self.y.columns, X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training all models and submitting prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-28T07:59:10.3229Z",
     "iopub.status.busy": "2022-04-28T07:59:10.322464Z",
     "iopub.status.idle": "2022-04-28T07:59:10.335461Z",
     "shell.execute_reply": "2022-04-28T07:59:10.334561Z",
     "shell.execute_reply.started": "2022-04-28T07:59:10.322868Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_prediction():\n",
    "    \"\"\"Trains a model for each store and saves the prediction\n",
    "    results into a csv file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_list = []\n",
    "    for store_nbr in stores['store_nbr'].unique():\n",
    "        store = Store(store_nbr = store_nbr)\n",
    "        prediction_list.append(store.train_and_predict())\n",
    "        print(f'finished predicting store {store_nbr}')\n",
    "\n",
    "    prediction = prediction_list[0]\n",
    "    for i in range(len(prediction_list) - 1):\n",
    "        prediction = prediction.append(prediction_list[i + 1])\n",
    "\n",
    "    final_submission = prediction[['id','sales']].sort_values('id').reset_index().drop('index', axis = 1)\n",
    "    final_submission.to_csv(\"submission.csv\", index=False)\n",
    "    return final_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = []\n",
    "# for store_nbr in stores['store_nbr'].unique():\n",
    "store = Store(store_nbr = 1)\n",
    "\n",
    "#     print(store.X_train.columns)\n",
    "#     prediction_list.append(store.train_and_predict())\n",
    "#     print(f'finished predicting store {store_nbr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=150, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=150, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=150, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.xgb_model.fit(store.X, store.y)   \n",
    "store.random_forest_model.fit(store.X, store.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- onpromotion - AUTOMOTIVE\n- onpromotion - BABY CARE\n- onpromotion - BEAUTY\n- onpromotion - BEVERAGES\n- onpromotion - BOOKS\n- ...\nFeature names seen at fit time, yet now missing:\n- AUTOMOTIVE\n- BABY CARE\n- BEAUTY\n- BEVERAGES\n- BOOKS\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m X_pred \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mget_input_for_prediction()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# X_pred\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# store.xgb_model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# store.X\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# y_pred_xgb_final = store.xgb_model.predict(X_pred)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m y_pred_random_forrest_final \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mrandom_forest_model\u001b[38;5;241m.\u001b[39mpredict(X_pred)\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- onpromotion - AUTOMOTIVE\n- onpromotion - BABY CARE\n- onpromotion - BEAUTY\n- onpromotion - BEVERAGES\n- onpromotion - BOOKS\n- ...\nFeature names seen at fit time, yet now missing:\n- AUTOMOTIVE\n- BABY CARE\n- BEAUTY\n- BEVERAGES\n- BOOKS\n- ...\n"
     ]
    }
   ],
   "source": [
    "# X_pred = store.get_input_for_prediction()\n",
    "# X_pred\n",
    "# store.xgb_model\n",
    "# store.X\n",
    "# y_pred_xgb_final = store.xgb_model.predict(X_pred)\n",
    "# y_pred_random_forrest_final = store.random_forest_model.predict(X_pred).clip(0.0)\n",
    "\n",
    "# y_pred = (y_pred_xgb_final + y_pred_random_forrest_final) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>onpromotion - AUTOMOTIVE</th>\n",
       "      <th>onpromotion - BABY CARE</th>\n",
       "      <th>onpromotion - BEAUTY</th>\n",
       "      <th>onpromotion - BEVERAGES</th>\n",
       "      <th>onpromotion - BOOKS</th>\n",
       "      <th>onpromotion - BREAD/BAKERY</th>\n",
       "      <th>onpromotion - CELEBRATION</th>\n",
       "      <th>onpromotion - CLEANING</th>\n",
       "      <th>onpromotion - DAIRY</th>\n",
       "      <th>...</th>\n",
       "      <th>onpromotion - MAGAZINES</th>\n",
       "      <th>onpromotion - MEATS</th>\n",
       "      <th>onpromotion - PERSONAL CARE</th>\n",
       "      <th>onpromotion - PET SUPPLIES</th>\n",
       "      <th>onpromotion - PLAYERS AND ELECTRONICS</th>\n",
       "      <th>onpromotion - POULTRY</th>\n",
       "      <th>onpromotion - PREPARED FOODS</th>\n",
       "      <th>onpromotion - PRODUCE</th>\n",
       "      <th>onpromotion - SCHOOL AND OFFICE SUPPLIES</th>\n",
       "      <th>onpromotion - SEAFOOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  onpromotion - AUTOMOTIVE  onpromotion - BABY CARE  \\\n",
       "0  2017-08-16                         0                        0   \n",
       "1  2017-08-17                         0                        0   \n",
       "2  2017-08-18                         0                        0   \n",
       "3  2017-08-19                         0                        0   \n",
       "4  2017-08-20                         0                        0   \n",
       "5  2017-08-21                         0                        0   \n",
       "6  2017-08-22                         0                        0   \n",
       "7  2017-08-23                         0                        0   \n",
       "8  2017-08-24                         0                        0   \n",
       "9  2017-08-25                         0                        0   \n",
       "10 2017-08-26                         0                        0   \n",
       "11 2017-08-27                         0                        0   \n",
       "12 2017-08-28                         0                        0   \n",
       "13 2017-08-29                         0                        0   \n",
       "14 2017-08-30                         0                        0   \n",
       "15 2017-08-31                         0                        0   \n",
       "\n",
       "    onpromotion - BEAUTY  onpromotion - BEVERAGES  onpromotion - BOOKS  \\\n",
       "0                      2                       20                    0   \n",
       "1                      1                       17                    0   \n",
       "2                      1                       12                    0   \n",
       "3                      1                       11                    0   \n",
       "4                      1                       10                    0   \n",
       "5                      1                       14                    0   \n",
       "6                      0                        9                    0   \n",
       "7                      1                       27                    0   \n",
       "8                      0                       26                    0   \n",
       "9                      0                       32                    0   \n",
       "10                     1                       32                    0   \n",
       "11                     1                       23                    0   \n",
       "12                     1                       31                    0   \n",
       "13                     1                       31                    0   \n",
       "14                     0                       35                    0   \n",
       "15                     1                       33                    0   \n",
       "\n",
       "    onpromotion - BREAD/BAKERY  onpromotion - CELEBRATION  \\\n",
       "0                           12                          0   \n",
       "1                            7                          0   \n",
       "2                           10                          0   \n",
       "3                            9                          0   \n",
       "4                            5                          0   \n",
       "5                           10                          0   \n",
       "6                            6                          0   \n",
       "7                           14                          0   \n",
       "8                            1                          0   \n",
       "9                            2                          0   \n",
       "10                           3                          0   \n",
       "11                           5                          0   \n",
       "12                           1                          0   \n",
       "13                           5                          0   \n",
       "14                           7                          0   \n",
       "15                           4                          0   \n",
       "\n",
       "    onpromotion - CLEANING  onpromotion - DAIRY  ...  onpromotion - MAGAZINES  \\\n",
       "0                       25                   45  ...                        0   \n",
       "1                        7                   13  ...                        0   \n",
       "2                        6                   18  ...                        0   \n",
       "3                       11                   20  ...                        0   \n",
       "4                        4                   17  ...                        0   \n",
       "5                        9                   20  ...                        0   \n",
       "6                       10                   18  ...                        0   \n",
       "7                       11                   22  ...                        0   \n",
       "8                       12                   13  ...                        0   \n",
       "9                        8                   12  ...                        0   \n",
       "10                      10                   12  ...                        0   \n",
       "11                       7                    7  ...                        0   \n",
       "12                      11                   12  ...                        0   \n",
       "13                      13                   13  ...                        0   \n",
       "14                      11                   16  ...                        0   \n",
       "15                      12                   11  ...                        0   \n",
       "\n",
       "    onpromotion - MEATS  onpromotion - PERSONAL CARE  \\\n",
       "0                     0                           18   \n",
       "1                     0                            7   \n",
       "2                    48                            9   \n",
       "3                     0                            9   \n",
       "4                     0                            7   \n",
       "5                     0                           11   \n",
       "6                     0                            9   \n",
       "7                     0                            8   \n",
       "8                     0                            7   \n",
       "9                    49                            7   \n",
       "10                    0                            8   \n",
       "11                    0                            6   \n",
       "12                    0                            6   \n",
       "13                    0                            5   \n",
       "14                    0                            6   \n",
       "15                    0                            8   \n",
       "\n",
       "    onpromotion - PET SUPPLIES  onpromotion - PLAYERS AND ELECTRONICS  \\\n",
       "0                            0                                      0   \n",
       "1                            0                                      0   \n",
       "2                            0                                      1   \n",
       "3                            0                                      1   \n",
       "4                            0                                      0   \n",
       "5                            0                                      1   \n",
       "6                            0                                      2   \n",
       "7                            0                                      0   \n",
       "8                            0                                      0   \n",
       "9                            0                                      0   \n",
       "10                           0                                      0   \n",
       "11                           0                                      0   \n",
       "12                           0                                      0   \n",
       "13                           0                                      1   \n",
       "14                           0                                      1   \n",
       "15                           0                                      0   \n",
       "\n",
       "    onpromotion - POULTRY  onpromotion - PREPARED FOODS  \\\n",
       "0                       0                             0   \n",
       "1                       1                             0   \n",
       "2                      41                             0   \n",
       "3                       0                             0   \n",
       "4                       0                             0   \n",
       "5                       0                             0   \n",
       "6                       1                             0   \n",
       "7                       0                             0   \n",
       "8                       0                             0   \n",
       "9                      36                             0   \n",
       "10                      0                             0   \n",
       "11                      0                             0   \n",
       "12                      0                             0   \n",
       "13                      0                             0   \n",
       "14                      0                             0   \n",
       "15                      0                             0   \n",
       "\n",
       "    onpromotion - PRODUCE  onpromotion - SCHOOL AND OFFICE SUPPLIES  \\\n",
       "0                     256                                        14   \n",
       "1                       6                                         0   \n",
       "2                       5                                         0   \n",
       "3                       6                                         0   \n",
       "4                       5                                         0   \n",
       "5                       3                                         0   \n",
       "6                       3                                         0   \n",
       "7                     211                                         0   \n",
       "8                       3                                         0   \n",
       "9                       1                                         0   \n",
       "10                      2                                         0   \n",
       "11                      0                                         0   \n",
       "12                      2                                         0   \n",
       "13                      1                                         0   \n",
       "14                    208                                         0   \n",
       "15                      3                                         0   \n",
       "\n",
       "    onpromotion - SEAFOOD  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       7  \n",
       "3                       0  \n",
       "4                       0  \n",
       "5                       0  \n",
       "6                       0  \n",
       "7                       0  \n",
       "8                       1  \n",
       "9                       5  \n",
       "10                      1  \n",
       "11                      0  \n",
       "12                      1  \n",
       "13                      0  \n",
       "14                      1  \n",
       "15                      0  \n",
       "\n",
       "[16 rows x 34 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_test.copy()\n",
    "df = df.set_index(['family','date']).sort_index().drop('id', axis = 1)\n",
    "\n",
    "X = df.loc[df['store_nbr'] == store.store_nbr].drop(['store_nbr'], axis = 1).unstack('family')\n",
    "X.columns = X.columns.map(' - '.join).str.strip(' - ')\n",
    "X = X.reset_index()\n",
    "# X = store.add_information(X)\n",
    "X\n",
    "# print(store.X.columns)\n",
    "\n",
    "# print(X_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['AUTOMOTIVE', 'BABY CARE', 'BEAUTY', 'BEVERAGES', 'BOOKS', 'BREAD/BAKERY', 'CELEBRATION', 'CLEANING', 'DAIRY', 'DELI', 'EGGS', 'FROZEN FOODS', 'GROCERY I', 'GROCERY II', 'HARDWARE', 'HOME AND KITCHEN I', 'HOME AND KITCHEN II', 'HOME APPLIANCES', 'HOME CARE', 'LADIESWEAR', 'LAWN AND GARDEN', 'LINGERIE', 'LIQUOR,WINE,BEER', 'MAGAZINES', 'MEATS', 'PERSONAL CARE', 'PET SUPPLIES', 'PLAYERS AND ELECTRONICS', 'POULTRY', 'PREPARED FOODS', 'PRODUCE', 'SCHOOL AND OFFICE SUPPLIES', 'SEAFOOD', 'dcoilwtico', 'dcoilwtico mean', 'dcoilwtico std', 'week sin', 'week cos', 'quarter sin', 'quarter cos', 'year sin', 'year cos', 'half decade sin', 'half decade cos', 'is new year', 'is work day', 'quarter', 'is payday', 'day of week_0', 'day of week_1', 'day of week_2', 'day of week_3', 'day of week_4', 'day of week_5', 'day of week_6'] ['onpromotion - AUTOMOTIVE', 'onpromotion - BABY CARE', 'onpromotion - BEAUTY', 'onpromotion - BEVERAGES', 'onpromotion - BOOKS', 'onpromotion - BREAD/BAKERY', 'onpromotion - CELEBRATION', 'onpromotion - CLEANING', 'onpromotion - DAIRY', 'onpromotion - DELI', 'onpromotion - EGGS', 'onpromotion - FROZEN FOODS', 'onpromotion - GROCERY I', 'onpromotion - GROCERY II', 'onpromotion - HARDWARE', 'onpromotion - HOME AND KITCHEN I', 'onpromotion - HOME AND KITCHEN II', 'onpromotion - HOME APPLIANCES', 'onpromotion - HOME CARE', 'onpromotion - LADIESWEAR', 'onpromotion - LAWN AND GARDEN', 'onpromotion - LINGERIE', 'onpromotion - LIQUOR,WINE,BEER', 'onpromotion - MAGAZINES', 'onpromotion - MEATS', 'onpromotion - PERSONAL CARE', 'onpromotion - PET SUPPLIES', 'onpromotion - PLAYERS AND ELECTRONICS', 'onpromotion - POULTRY', 'onpromotion - PREPARED FOODS', 'onpromotion - PRODUCE', 'onpromotion - SCHOOL AND OFFICE SUPPLIES', 'onpromotion - SEAFOOD', 'dcoilwtico', 'dcoilwtico mean', 'dcoilwtico std', 'week sin', 'week cos', 'quarter sin', 'quarter cos', 'year sin', 'year cos', 'half decade sin', 'half decade cos', 'is new year', 'is work day', 'quarter', 'is payday', 'day of week_0', 'day of week_1', 'day of week_2', 'day of week_3', 'day of week_4', 'day of week_5', 'day of week_6']\nexpected AUTOMOTIVE, HOME AND KITCHEN II, HOME AND KITCHEN I, SEAFOOD, DAIRY, EGGS, FROZEN FOODS, HOME APPLIANCES, HARDWARE, PERSONAL CARE, CLEANING, GROCERY II, LIQUOR,WINE,BEER, BABY CARE, BOOKS, PET SUPPLIES, SCHOOL AND OFFICE SUPPLIES, DELI, LINGERIE, MEATS, MAGAZINES, BEAUTY, PRODUCE, PLAYERS AND ELECTRONICS, BREAD/BAKERY, GROCERY I, POULTRY, BEVERAGES, HOME CARE, LAWN AND GARDEN, CELEBRATION, PREPARED FOODS, LADIESWEAR in input data\ntraining data did not have the following fields: onpromotion - LADIESWEAR, onpromotion - EGGS, onpromotion - SEAFOOD, onpromotion - LAWN AND GARDEN, onpromotion - FROZEN FOODS, onpromotion - BEVERAGES, onpromotion - GROCERY I, onpromotion - GROCERY II, onpromotion - DELI, onpromotion - PRODUCE, onpromotion - LIQUOR,WINE,BEER, onpromotion - MAGAZINES, onpromotion - BREAD/BAKERY, onpromotion - HOME AND KITCHEN I, onpromotion - HOME CARE, onpromotion - HARDWARE, onpromotion - PET SUPPLIES, onpromotion - BEAUTY, onpromotion - LINGERIE, onpromotion - DAIRY, onpromotion - CELEBRATION, onpromotion - PREPARED FOODS, onpromotion - POULTRY, onpromotion - BABY CARE, onpromotion - HOME AND KITCHEN II, onpromotion - BOOKS, onpromotion - CLEANING, onpromotion - HOME APPLIANCES, onpromotion - SCHOOL AND OFFICE SUPPLIES, onpromotion - MEATS, onpromotion - PERSONAL CARE, onpromotion - PLAYERS AND ELECTRONICS, onpromotion - AUTOMOTIVE",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m submission \u001b[38;5;241m=\u001b[39m make_prediction()\n",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m, in \u001b[0;36mmake_prediction\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store_nbr \u001b[38;5;129;01min\u001b[39;00m stores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_nbr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      9\u001b[0m     store \u001b[38;5;241m=\u001b[39m Store(store_nbr \u001b[38;5;241m=\u001b[39m store_nbr)\n\u001b[1;32m---> 10\u001b[0m     prediction_list\u001b[38;5;241m.\u001b[39mappend(store\u001b[38;5;241m.\u001b[39mtrain_and_predict())\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished predicting store \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore_nbr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m prediction \u001b[38;5;241m=\u001b[39m prediction_list[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[7], line 93\u001b[0m, in \u001b[0;36mStore.train_and_predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_forest_model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     91\u001b[0m X_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_input_for_prediction()\n\u001b[1;32m---> 93\u001b[0m y_pred_xgb_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxgb_model\u001b[38;5;241m.\u001b[39mpredict(X_pred)\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m     94\u001b[0m y_pred_random_forrest_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_forest_model\u001b[38;5;241m.\u001b[39mpredict(X_pred)\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m     96\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_pred_xgb_final \u001b[38;5;241m+\u001b[39m y_pred_random_forrest_final) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\multioutput.py:248\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a predict method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m y \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    249\u001b[0m     delayed(e\u001b[38;5;241m.\u001b[39mpredict)(X) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\n\u001b[0;32m    250\u001b[0m )\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\xgboost\\sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1114\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1115\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1116\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1117\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1118\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1119\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1120\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1121\u001b[0m         )\n\u001b[0;32m   1122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\xgboost\\core.py:2285\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2283\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2285\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fns)\n\u001b[0;32m   2287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   2288\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\xgboost\\core.py:2779\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   2773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   2774\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2775\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2776\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   2777\u001b[0m     )\n\u001b[1;32m-> 2779\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['AUTOMOTIVE', 'BABY CARE', 'BEAUTY', 'BEVERAGES', 'BOOKS', 'BREAD/BAKERY', 'CELEBRATION', 'CLEANING', 'DAIRY', 'DELI', 'EGGS', 'FROZEN FOODS', 'GROCERY I', 'GROCERY II', 'HARDWARE', 'HOME AND KITCHEN I', 'HOME AND KITCHEN II', 'HOME APPLIANCES', 'HOME CARE', 'LADIESWEAR', 'LAWN AND GARDEN', 'LINGERIE', 'LIQUOR,WINE,BEER', 'MAGAZINES', 'MEATS', 'PERSONAL CARE', 'PET SUPPLIES', 'PLAYERS AND ELECTRONICS', 'POULTRY', 'PREPARED FOODS', 'PRODUCE', 'SCHOOL AND OFFICE SUPPLIES', 'SEAFOOD', 'dcoilwtico', 'dcoilwtico mean', 'dcoilwtico std', 'week sin', 'week cos', 'quarter sin', 'quarter cos', 'year sin', 'year cos', 'half decade sin', 'half decade cos', 'is new year', 'is work day', 'quarter', 'is payday', 'day of week_0', 'day of week_1', 'day of week_2', 'day of week_3', 'day of week_4', 'day of week_5', 'day of week_6'] ['onpromotion - AUTOMOTIVE', 'onpromotion - BABY CARE', 'onpromotion - BEAUTY', 'onpromotion - BEVERAGES', 'onpromotion - BOOKS', 'onpromotion - BREAD/BAKERY', 'onpromotion - CELEBRATION', 'onpromotion - CLEANING', 'onpromotion - DAIRY', 'onpromotion - DELI', 'onpromotion - EGGS', 'onpromotion - FROZEN FOODS', 'onpromotion - GROCERY I', 'onpromotion - GROCERY II', 'onpromotion - HARDWARE', 'onpromotion - HOME AND KITCHEN I', 'onpromotion - HOME AND KITCHEN II', 'onpromotion - HOME APPLIANCES', 'onpromotion - HOME CARE', 'onpromotion - LADIESWEAR', 'onpromotion - LAWN AND GARDEN', 'onpromotion - LINGERIE', 'onpromotion - LIQUOR,WINE,BEER', 'onpromotion - MAGAZINES', 'onpromotion - MEATS', 'onpromotion - PERSONAL CARE', 'onpromotion - PET SUPPLIES', 'onpromotion - PLAYERS AND ELECTRONICS', 'onpromotion - POULTRY', 'onpromotion - PREPARED FOODS', 'onpromotion - PRODUCE', 'onpromotion - SCHOOL AND OFFICE SUPPLIES', 'onpromotion - SEAFOOD', 'dcoilwtico', 'dcoilwtico mean', 'dcoilwtico std', 'week sin', 'week cos', 'quarter sin', 'quarter cos', 'year sin', 'year cos', 'half decade sin', 'half decade cos', 'is new year', 'is work day', 'quarter', 'is payday', 'day of week_0', 'day of week_1', 'day of week_2', 'day of week_3', 'day of week_4', 'day of week_5', 'day of week_6']\nexpected AUTOMOTIVE, HOME AND KITCHEN II, HOME AND KITCHEN I, SEAFOOD, DAIRY, EGGS, FROZEN FOODS, HOME APPLIANCES, HARDWARE, PERSONAL CARE, CLEANING, GROCERY II, LIQUOR,WINE,BEER, BABY CARE, BOOKS, PET SUPPLIES, SCHOOL AND OFFICE SUPPLIES, DELI, LINGERIE, MEATS, MAGAZINES, BEAUTY, PRODUCE, PLAYERS AND ELECTRONICS, BREAD/BAKERY, GROCERY I, POULTRY, BEVERAGES, HOME CARE, LAWN AND GARDEN, CELEBRATION, PREPARED FOODS, LADIESWEAR in input data\ntraining data did not have the following fields: onpromotion - LADIESWEAR, onpromotion - EGGS, onpromotion - SEAFOOD, onpromotion - LAWN AND GARDEN, onpromotion - FROZEN FOODS, onpromotion - BEVERAGES, onpromotion - GROCERY I, onpromotion - GROCERY II, onpromotion - DELI, onpromotion - PRODUCE, onpromotion - LIQUOR,WINE,BEER, onpromotion - MAGAZINES, onpromotion - BREAD/BAKERY, onpromotion - HOME AND KITCHEN I, onpromotion - HOME CARE, onpromotion - HARDWARE, onpromotion - PET SUPPLIES, onpromotion - BEAUTY, onpromotion - LINGERIE, onpromotion - DAIRY, onpromotion - CELEBRATION, onpromotion - PREPARED FOODS, onpromotion - POULTRY, onpromotion - BABY CARE, onpromotion - HOME AND KITCHEN II, onpromotion - BOOKS, onpromotion - CLEANING, onpromotion - HOME APPLIANCES, onpromotion - SCHOOL AND OFFICE SUPPLIES, onpromotion - MEATS, onpromotion - PERSONAL CARE, onpromotion - PLAYERS AND ELECTRONICS, onpromotion - AUTOMOTIVE"
     ]
    }
   ],
   "source": [
    "submission = make_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some possible improvements\n",
    "* Use grid search to choose better hyperparameters, which also implies setting more hyperparameters for training the XGBoost and Random Forest models. However, this is expected to take a really long time.\n",
    "* Explore other types of models for prediction such as Support Vector Machines and Linear Regression, or a combination of them.\n",
    "* Create different models for each product family as opposed to each store.\n",
    "* Explore more preprocessing options to deal with the available data, such as changing how the model deals with events and holidays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
